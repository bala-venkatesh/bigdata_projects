{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhDS7J3gr2eyAOqP5sftCI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrKtK4N9RD5-",
        "outputId": "3b260380-767d-43af-9de0-fbda69c94474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting asyncpraw\n",
            "  Downloading asyncpraw-7.8.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting aiofiles (from asyncpraw)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.11.2)\n",
            "Collecting aiosqlite<=0.17.0 (from asyncpraw)\n",
            "  Downloading aiosqlite-0.17.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting asyncprawcore<3,>=2.1 (from asyncpraw)\n",
            "  Downloading asyncprawcore-2.4.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting update_checker>=0.18 (from asyncpraw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update_checker>=0.18->asyncpraw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update_checker>=0.18->asyncpraw) (2024.8.30)\n",
            "Downloading asyncpraw-7.8.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiosqlite-0.17.0-py3-none-any.whl (15 kB)\n",
            "Downloading asyncprawcore-2.4.0-py3-none-any.whl (19 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: aiosqlite, aiofiles, update_checker, asyncprawcore, asyncpraw\n",
            "Successfully installed aiofiles-24.1.0 aiosqlite-0.17.0 asyncpraw-7.8.0 asyncprawcore-2.4.0 update_checker-0.18.0\n"
          ]
        }
      ],
      "source": [
        "pip install asyncpraw"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncpraw\n",
        "\n",
        "# Define the async function\n",
        "async def fetch_reddit_posts():\n",
        "    async with asyncpraw.Reddit(\n",
        "        client_id=\"client id\",         # Replace with your client ID\n",
        "        client_secret=\"client secret\", # Replace with your client secret\n",
        "        user_agent=\"MyRedditScript/1.0 by u/username\"\n",
        "    ) as reddit:  # This ensures the session is properly closed when done\n",
        "\n",
        "      # Access the subreddit\n",
        "      subreddit = await reddit.subreddit(\"bigdata\")\n",
        "\n",
        "      # Fetch and print the top 5 hot posts\n",
        "      print(\"Top posts from r/bigdata:\")\n",
        "      async for post in subreddit.hot(limit=10):\n",
        "        print(f\"Title: {post.title}\\nScore: {post.score}\\nURL: {post.url}\\n\")\n",
        "\n",
        "# Since we're in a notebook, directly use `await` to run the function\n",
        "await fetch_reddit_posts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xIIMRuVRG4U",
        "outputId": "3242c6f2-5561-431e-d727-46ab653b3bf7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top posts from r/bigdata:\n",
            "Title: Unfolding the Role of Black Box and Explainable AI in Data Science\n",
            "Score: 1\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h39503/unfolding_the_role_of_black_box_and_explainable/\n",
            "\n",
            "Title: Hive Setting Lookup\n",
            "Score: 1\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h32p1o/hive_setting_lookup/\n",
            "\n",
            "Title: I have a data processing scenario. suggested architectural choices\n",
            "Score: 3\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h2cq3v/i_have_a_data_processing_scenario_suggested/\n",
            "\n",
            "Title: Domain\n",
            "Score: 1\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h27wg7/domain/\n",
            "\n",
            "Title: Geospatial Data Analysis with Teradata Vantage \n",
            "Score: 0\n",
            "URL: https://youtu.be/Claa4iXHr0U?si=WpFrUPScIJnSYzBs\n",
            "\n",
            "Title: Boost Your Credibility with Data Science Certifications\n",
            "Score: 0\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h1upu0/boost_your_credibility_with_data_science/\n",
            "\n",
            "Title: Achieving Sub-Second Latency with S3 Storage—A Kafka Alternative Using Pathway\n",
            "Score: 9\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h19gg9/achieving_subsecond_latency_with_s3_storagea/\n",
            "\n",
            "Title: 10 Use Cases for Dremio in Your Data Architecture\n",
            "Score: 0\n",
            "URL: https://medium.com/data-engineering-with-dremio/10-use-cases-for-dremio-in-your-data-architecture-64a98d2be8bc\n",
            "\n",
            "Title: Looking for API/Database to Identify Companies Behind IP Addresses (Not ISPs)\n",
            "Score: 1\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h1bm38/looking_for_apidatabase_to_identify_companies/\n",
            "\n",
            "Title: Unlock the Power of Data Science Framework for Business Growth\n",
            "Score: 1\n",
            "URL: https://www.reddit.com/r/bigdata/comments/1h0yv0p/unlock_the_power_of_data_science_framework_for/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ph8ZZCKQRzug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}